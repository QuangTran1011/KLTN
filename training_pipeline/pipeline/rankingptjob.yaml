apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: ranking-train
  namespace: kubeflow
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        metadata:
          annotations:
            iam.gke.io/gcp-service-account: "164485441658-compute@developer.gserviceaccount.com"
        spec:
          serviceAccountName: default
          containers:
            - name: pytorch
              image: quangtran1011/training_pipeline:v19
              command: 
                - python
                - -m
                - src.ranking
              env:
                - name: PYTHONUNBUFFERED
                  value: "1"
                - name: OMP_NUM_THREADS
                  value: "2"
                - name: MLFLOW_TRACKING_URI
                  value: "http://34.172.241.248:8080"
                - name: MASTER_ADDR
                  value: "ranking-train-master-0"
                - name: MASTER_PORT
                  value: "23456"
                - name: WORLD_SIZE
                  value: "2"  # Master + Worker
                - name: RANK
                  value: "0"  # Master rank
              resources:
                limits:
                  memory: "10Gi"
                  cpu: "1"
                requests:
                  memory: "8Gi"
                  cpu: "1"
              volumeMounts:
                - name: data
                  mountPath: /mnt/pvc
                - name: dshm
                  mountPath: /dev/shm
          volumes:
            - name: data
              persistentVolumeClaim:
                claimName: skipgram-pvc
            - name: dshm
              emptyDir:
                medium: Memory
                sizeLimit: "2Gi"
                
    Worker:
      replicas: 1
      restartPolicy: OnFailure
      template:
        metadata:
          annotations:
            iam.gke.io/gcp-service-account: "164485441658-compute@developer.gserviceaccount.com"
        spec:
          serviceAccountName: default
          containers:
            - name: pytorch
              image: quangtran1011/training_pipeline:v19
              command: 
                - python
                - -m
                - src.ranking
              env:
                - name: PYTHONUNBUFFERED
                  value: "1"
                - name: OMP_NUM_THREADS
                  value: "2"
                - name: MLFLOW_TRACKING_URI
                  value: "http://34.172.241.248:8080"
                - name: MASTER_ADDR
                  value: "ranking-train-master-0"
                - name: MASTER_PORT
                  value: "23456"
                - name: WORLD_SIZE
                  value: "2"  # Master + Worker
                - name: RANK
                  value: "1"  # Worker rank
              resources:
                limits:
                  memory: "10Gi"
                  cpu: "1"
                requests:
                  memory: "8Gi"
                  cpu: "1"
              volumeMounts:
                - name: data
                  mountPath: /mnt/pvc
                - name: dshm
                  mountPath: /dev/shm
          volumes:
            - name: data
              persistentVolumeClaim:
                claimName: skipgram-pvc
            - name: dshm
              emptyDir:
                medium: Memory
                sizeLimit: "2Gi"